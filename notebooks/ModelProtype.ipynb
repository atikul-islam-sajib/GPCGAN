{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6.6%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/raw/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/raw/MNIST/raw/train-images-idx3-ubyte.gz to ../data/raw/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/raw/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/raw/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/raw/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/raw/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/raw/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/raw/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/raw/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/raw/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/raw/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "mnist_data = datasets.MNIST(\n",
    "    root=\"../data/raw/\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True,\n",
    ")\n",
    "dataloader = DataLoader(mnist_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total quantity of the dataset # 60000\n",
      "The shape of the dataset # torch.Size([32, 1, 28, 28]) \n"
     ]
    }
   ],
   "source": [
    "# check the quantity of the dataset\n",
    "total_data = 0\n",
    "\n",
    "for data, label in dataloader:\n",
    "    total_data+=data.shape[0]\n",
    "\n",
    "print(\"The total quantity of the dataset # {}\".format(total_data))\n",
    "print(\"The shape of the dataset # {} \".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device # mps \n"
     ]
    }
   ],
   "source": [
    "# Call the GPU - MAC\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Device # {} \".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    A generator class for a Generative Adversarial Network (GAN), particularly used for\n",
    "    generating images. It takes a latent space vector and a label as input and generates\n",
    "    images corresponding to the input label. It utilizes fully connected layers and\n",
    "    LeakyReLU activation for intermediate layers, with a Tanh activation for the output layer.\n",
    "\n",
    "    Attributes:\n",
    "        latent_space (int): Dimensionality of the latent space vector (z), which is a random\n",
    "                            noise input for the generator.\n",
    "        num_labels (int): Number of unique labels for the conditional GAN. It corresponds to\n",
    "                          the number of different classes in the dataset.\n",
    "        labels (nn.Embedding): Embedding layer for the labels, allowing the generator to use\n",
    "                               label information to generate images corresponding to specific classes.\n",
    "        layers_config (list): A list defining the architecture of the neural network. Each\n",
    "                              element in the list is a tuple, with the first two elements\n",
    "                              being the number of input and output features for a layer,\n",
    "                              and the optional third being the negative slope for LeakyReLU.\n",
    "        model (nn.Sequential): The actual neural network model, constructed based on layers_config.\n",
    "                               It comprises fully connected (Linear) layers, LeakyReLU activation\n",
    "                               for non-linearity in intermediate layers, and a Tanh activation function\n",
    "                               in the output layer for generating pixel values.\n",
    "\n",
    "    Methods:\n",
    "        connected_layer(layers_config=None):\n",
    "            Constructs the neural network layers based on layers_config. It initializes the fully\n",
    "            connected layers and the activation functions, specifically using LeakyReLU for intermediate\n",
    "            layers and Tanh for the output layer.\n",
    "\n",
    "        forward(x, labels):\n",
    "            Performs a forward pass of the generator. It takes a latent space vector `x` and its\n",
    "            corresponding labels, processes them through the network, and generates a batch of images.\n",
    "\n",
    "    Note:\n",
    "        - The latent space vector x should be of the shape (N, latent_space) where N is the batch size.\n",
    "        - Labels should be of shape (N,) and contain integers representing class labels.\n",
    "        - The output is a tensor of shape (N, 1, 28, 28), representing generated images of size 28x28 pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_space=100, num_labels=10):\n",
    "        self.latent_space = latent_space\n",
    "        self.num_labels = num_labels\n",
    "        super(Generator, self).__init__()\n",
    "        self.labels = nn.Embedding(self.num_labels, self.num_labels)\n",
    "        self.layers_config = [\n",
    "            (self.latent_space + self.num_labels, 256, 0.2),\n",
    "            (256, 512, 0.2),\n",
    "            (512, 1024, 0.2),\n",
    "            (1024, 784),\n",
    "        ]\n",
    "        self.model = self.connected_layer(layers_config=self.layers_config)\n",
    "\n",
    "    def connected_layer(self, layers_config=None):\n",
    "        layers = OrderedDict()\n",
    "        if layers_config is not None:\n",
    "            for index, (in_features, out_features, negative_slope) in enumerate(\n",
    "                layers_config[:-1]\n",
    "            ):\n",
    "                layers[\"{}_layer\".format(index)] = nn.Linear(\n",
    "                    in_features=in_features, out_features=out_features\n",
    "                )\n",
    "                layers[\"{}_activation\".format(index)] = nn.LeakyReLU(\n",
    "                    negative_slope=negative_slope\n",
    "                )\n",
    "\n",
    "            (in_features, out_features) = layers_config[-1]\n",
    "            layers[\"output_layer\"] = nn.Linear(\n",
    "                in_features=in_features, out_features=out_features\n",
    "            )\n",
    "            layers[\"output_activation\"] = nn.Tanh()\n",
    "\n",
    "            return nn.Sequential(layers)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"No layers config provided\".capitalize())\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        if x is not None:\n",
    "            labels = self.labels(labels)\n",
    "            x = torch.cat([x, labels], dim=1)\n",
    "            x = self.model(x)\n",
    "        else:\n",
    "            raise Exception(\"No input provided in Generator\".capitalize())\n",
    "\n",
    "        return x.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Generator()\n",
    "noise_data = torch.randn(64, 100)\n",
    "data, labels = next(iter(dataloader))\n",
    "\n",
    "g(noise_data, labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    A discriminator class for a Generative Adversarial Network (GAN), particularly used for\n",
    "    image data with an added conditional label embedding. The discriminator's goal is to\n",
    "    differentiate between real and fake images. It utilizes fully connected layers,\n",
    "    LeakyReLU activation for hidden layers, and a Sigmoid activation for the output layer.\n",
    "\n",
    "    Attributes:\n",
    "        num_labels (int): Number of unique labels for the conditional GAN. For instance,\n",
    "                          in a dataset with 10 different classes, num_labels should be 10.\n",
    "        labels (nn.Embedding): Embedding layer for the labels, which allows the discriminator\n",
    "                               to condition the input on a particular class.\n",
    "        layers_config (list): A list defining the architecture of the neural network. Each\n",
    "                              element in the list is a tuple, with the first two elements\n",
    "                              being the number of input and output features for a layer,\n",
    "                              and the optional third being the negative slope for LeakyReLU.\n",
    "        model (nn.Sequential): The actual neural network model, constructed based on layers_config.\n",
    "                              It comprises fully connected (Linear) layers, LeakyReLU activation\n",
    "                              for non-linearity in hidden layers, and a Sigmoid activation function\n",
    "                              in the output layer to obtain probabilities.\n",
    "\n",
    "    Methods:\n",
    "        connected_layer(layers_config=None):\n",
    "            Constructs the neural network layers based on layers_config. It initializes the fully\n",
    "            connected layers and the activation functions, specifically using LeakyReLU for hidden\n",
    "            layers and Sigmoid for the output layer.\n",
    "\n",
    "        forward(x, labels):\n",
    "            Performs a forward pass of the discriminator. It takes an input batch of images `x`\n",
    "            and their corresponding labels, processes the images and labels through the network,\n",
    "            and outputs a batch of probabilities indicating how likely each image is to be real.\n",
    "\n",
    "    Note:\n",
    "        - The model expects inputs x to be of the shape (N, 784) where N is the batch size.\n",
    "        - Labels should be of shape (N,) and contain integers representing class labels.\n",
    "        - The output is of shape (N, 1), representing the likelihood of each image being real.\n",
    "        - The network architecture is designed to work with flattened images of size 28x28 pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_labels=10):\n",
    "        self.num_labels = num_labels\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.labels = nn.Embedding(self.num_labels, self.num_labels)\n",
    "        self.layers_config = [\n",
    "            (784 + self.num_labels, 512, 0.2),\n",
    "            (512, 256, 0.2),\n",
    "            (256, 1),\n",
    "        ]\n",
    "        self.model = self.connected_layer(layers_config=self.layers_config)\n",
    "\n",
    "    def connected_layer(self, layers_config=None):\n",
    "        layers = OrderedDict()\n",
    "        if layers_config is not None:\n",
    "            for index, (in_features, out_features, negative_slope) in enumerate(\n",
    "                layers_config[:-1]\n",
    "            ):\n",
    "                layers[\"{}_layer\".format(index + 1)] = nn.Linear(\n",
    "                    in_features=in_features, out_features=out_features\n",
    "                )\n",
    "                layers[\"{}_activation\".format(index + 1)] = nn.LeakyReLU(\n",
    "                    negative_slope=negative_slope\n",
    "                )\n",
    "\n",
    "            (in_features, out_features) = layers_config[-1]\n",
    "            layers[\"output_layer\"] = nn.Linear(\n",
    "                in_features=in_features, out_features=out_features\n",
    "            )\n",
    "            layers[\"output_activation\"] = nn.Sigmoid()\n",
    "\n",
    "            return nn.Sequential(layers)\n",
    "        else:\n",
    "            raise Exception(\"Layers config is not defined properly\".capitalize())\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        if x is not None:\n",
    "            labels = self.labels(labels)\n",
    "            x = x.reshape(-1, 28 * 28)\n",
    "            x = torch.cat([x, labels], dim=1)\n",
    "            x = self.model(x)\n",
    "        else:\n",
    "            raise Exception(\"Inputs are not defined properly\".capitalize())\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Discriminator()\n",
    "\n",
    "data, label = next(iter(dataloader))\n",
    "d(data, label).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Discriminator()\n",
    "\n",
    "data = torch.randn(64, 1, 28, 28)\n",
    "\n",
    "d(data, label).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    x = (64, 1, 28, 28)\n",
    "    labels = (64, 10)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
